MYSQL 教程

* 学习地址
   - [索引](https://www.cnblogs.com/zhangxufeng/p/8308558.html)
   - [数据库事务/锁/隔离级别原理](https://www.cnblogs.com/crazylqy/p/7611069.html)
* 问题
   - 对于模糊查询的解决方案（解决）
   - show status like 'Handler_read%' 的解释（半解决，视频未作详细的说明）
   - show profile for query 序列号
      - 查询出来的 Sending data 是什么意思
   - mysql 默认日志格式是什么？MIX 还是 STATEMENT？

* 索引类型
   - BTREE 索引：最常见的索引类型，大部分索引都支持 B 树索引
   - HASH 索引：只有 Memory 引擎支持，使用场景简单
   - R-tree 索引：空间索引，空间索引是 MyISAM 引擎的一个特殊索引类型，主要用于地理空间数据类型，通常使用较少，不做特别介绍
   - Full-text 全文索引：全文索引也是 MyISAM的一个特殊索引类型，主要用于全文索引，InnoDB从Mysql5.6版本开始支持全文索引

* 索引的建立
   - 索引的一些命令
      - 创建索引：CREATE [UNIQUE|FULL TEXT|SPATIAL] INDEX 索引名 [USING index_type] ON 表名(column1[,column2,...])
      - 查看索引：SHOW INDEX FROM 表名
      - 删除索引：DROP INDEX 索引名 ON 表名
      - 修改索引：ALTER TABLE 表名 add primary|unique|index|fulltext 索引名(column1[,column2,...])

* SQL 性能监测命令
   1. show processlist：查看当前 mysql 在进行的线程，包括id，用户名和地址，库，命令，时间，sql语句
      - 注意这条命令执行的是在执行状态情况
      - 可以用来查看当前已经锁表或在进行的慢sql情况
      - Time 是 sql语句到执行 show processlist 已经过了几秒
      - Status 是相应 sql 语句的状态
   2. show [session|global] status 命令
      0. 可以查看提供服务器状态信息
         - session 当前连接，global 是自数据库上次启动至今的统计结果，如果不写则默认为 session
      1. show [] status like 'Com_______';                 # 查看插入，删除，修改，查询命令次数执行等（有匹配了Com开头后面七个字符）
      2. show [] status like 'Innodb_rows_%';              # 查看 innodb 有关的数据行的数据
      3. show open tables;                              # 查看每张表的锁情况
         - in_user：表当前被查询使用的次数，如果该次数为零，则表是打开的，但是当前没有被使用
         - Name_locked：表名称是否被锁定，名称锁定用于取消表或对表进行重命名等操作
      4. show [] status like 'Table%'                      # 查询总的锁次数情况，缓存的命中的情况
         - Table_locks_immediate：指的是能够立即获得表级锁的次数，每立即获取锁，值加 1
         - table_locks_waited：指的是不能立即获取表级锁而需要等待的次数，每等待一次，该值加1,此值高说明存在较为严重的表级锁争用情况
      5. show [] status like 'Innodb_row_lock%'            # 查看行锁的竞争情况
         - Innodb_row_lock_current_waits 当前正在等待行锁的数量
         - Innodb_row_lock_time 从系统到现在锁定总时间长度
         - Innodb_row_lock_time_avg 每次平均所花平均时长
         - Innodb_row_lock_time_max 从系统启动到现在等待最长的一次所花的时间
         - Innodb_row_lock_waits 系统启动后到现在总共等待的次数
      6. show [] status like 'Handler_read%'               # 查询索引使用情况
      7. show [] status like 'Qcache%'                     # 查询缓存的状态信息

* 定位低效的执行 sql
   - 慢查询日志：用 --log-slow-queries[=file_name]选项启动时，mysqld 写一个包含所有执行时间超过 long_query_time 秒的 sql 语句日志文件
   - show processlist：查看当前 mysql 在进行的线程，包括id，用户名和地址，库，命令，时间，sql语句
      - 注意这条命令执行的是在执行状态情况
      - 可以用来查看当前已经锁表或在进行的慢sql情况
      - Time 是 sql语句到执行 show processlist 已经过了几秒
      - Status 是相应 sql 语句的状态

* 执行sql分析
   - explain sql语句
      - https://segmentfault.com/a/1190000021458117?utm_source=tag-newest
      ```
      格式
      id select_type table type possible_keys key key_len ref rows Extra

      解析
      id 
         select查询的序列号，是一组数字，表示的是查询中执行select子句或者是操作表的顺序（一个复杂sql语句可能会分为几条数据，id最大的则是最先执行的，在子查询中通常一般是最内子查询）
      select_type 
         表示select的类型
         SIMPLE 简单的 select 查询，查询中不包含子查询或者 UNION
         PRIMARY 查询中若包含任何复杂的子查询，最底层查询标记为该标识
         SUBQUERY 在select或where列表中包含了子查询
         DERIVED 在FROM列表中包含的子查询，被标记为DERIVED（衍生）MYSQL会递归执行这些子查询，把结果放在临时表中
         UNION 若第二个SELECT出现在UNION之后，则标记为UNION；若UNION包含在FROM子句的查询中，外层SELECT将被标记为：DERIVED
         UNION RESULT 从UNION表获取结果的SELECT
      type 
         表示表的连接类型，性能由好到差的连接类型为system->const->eq_ref->ref->ref_or_null->index_merge->index_subquery->range->index->all
         NULL 表示mysql不访问任何表，索引，直接返回结果
         system 表示只有一行记录（等于系统表），这是const类型的特殊，一般不会出现
         const 表示通过索引一次就找到了，const用于比较 primary key 或者 unique 索引，因为只匹配一行数据，所以很快，如将主键置于where列表中，
               mysql就能将该查询转换为一个常量，const于将“主键”或“唯一”索引的所有部分与常量值进行比较
         eq_ref 类似ref，区别在于使用的是唯一索引，使用主键的关联查询，关联查询出的记录只有一条，常见于主键或唯一索引扫描
         ref 非唯一性索引扫描，返回匹配某个单独值的所有行，本质上也是一种索引访问，返回所有匹配某个单独值的所有行（多个）
         range 只检索给定返回的行，使用一个索引来选择行，where 之后出现 between,<,>,in 等操作
         index index与ALL的区别为 index 类型只是遍历了索引树，通常比ALL快，ALL是遍历数据文件
         all 将遍历表以找到匹配的行
      possible_keys 
         表示查询时，可能使用的索引
      key 
         表示实际使用的索引
      key_len 
         索引字段的长度
      rows 
         扫描行的数量
      extra 
         执行情况的说明和描述
         using filesort 说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取，称为“文件排序”
         using temporary 使用了临时表保存中间结果，mysql在对查询结果排序时使用临时表，常见于order by 和 group by
         using index 表示相应的select操作使用了覆盖索引，查询字段是索引的字段，即使有where条件也是索引前缀，避免访问表的数据行，效率不错
         using where 在查询语句中，使用了条件查询，查询条件没有索引前缀，查询内容也没有索引字段
         using index condition 查找使用了索引，但是查询字段仍有非索引字段需要回表查询 或 还需要 where 条件的非条件过滤进行回表查询
         using index;using where 查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回表查询
      ```

   - show profiles 分析sql
      - 检测开启和开启功能
         - 能够在做 sql 优化时帮助我们了解时间都耗费在哪里去了
         - select @@have_profiling 查看是否支持此功能
         - select @@profiling 查看是否开始此功能，只对当前会话有效
         - set profiling=1 开始profiling 开关
      - show profiles 可以查看到 sql 语句执行了多少时间
         ```
         Query_ID 具体sql的id号
         Duration sql的执行时间
         Query 具体的sql内容
         ```
      - 查看具体的sql详情
         - show profile [可用参数1,[可用参数2...]] for query sql号
            - 可用参数为：
               - ALL 显示所有的开销
               - BLOCK IO 显示块IO相关开销
               - CONTEXT SWITCHES 上下文切换相关开销
               - CPU 显示CPU相关开销信息
               - IPC 显示发送和接收相关开销信息
               - MEMORY 显示内在相关开销信息
               - PAGE FAULTS 显示页面错误相关开销信息
               - SOURCE 显示和 Source_function, Source_file, Source_line 相关的开销信息
               - SWAPS 显示交换次数相关开销信息
            - 坏情况
               - converting HEAP to MYISAM 查询结果太大，内存不够用，往磁盘写入
               - Creating tmp table 创建临时表
               - Copying to tmp table on disk 把内存中的临时表复制到磁盘！危险！！
               - locked 有锁
            - 全局查询日志，强烈不建议生产环境使用！！
               - SHOW VARIABLES LIKE '%general%'
               - SELECT * FROM mysql.general_log
            ```
            可以得到 sql 从进入sql接口到解析最后关闭连接等系列耗费的时间
            ```

   - trace 分析优化器执行计划
      - 开启 trace
         - 通过 trace 文件能够进行一步了解优化器选择A计划，而不是B计划
         - 打开 trace，设置格式为 JSON， 并设置 trace 最大能够使用的内存大小，避免解析过程中因为默认内存过小而不能够完整展示
         - SET optimizer_trace="enabled=on",end_markers_in_json=on;
         - SET optimizer_trace_max_mem_size=1000000;
      - 检测
         - 执行sql语句： select * from 表 where id < 4;
         - 查询之前sql的优化：select * from information_schema.optimizer_trace\G;

* 索引的使用和避免失效
   - 索引失效总结
      1. like 查询没有前缀或后缀
      2. 复合索引不遵守最左原则
      3. 索引用以计算
      4. 不等号，or 会造成索引失效
      5. 字符串引号 掉了
      6. 分组之前必排序，没有上索引
      7. 索引字段的数据分布过于单一（有一个公式），sql优化器会判断查索引不如扫全表（比如 男/女 字段）
   - (name status address) 联合索引，都是字符串类型
      - 索引全失效（完全不符合最左索引原则）
         - 最左索引是指条件中是否包含 创建复合索引时，作为第一个索引字段的 字段，这里是 name
         - select * from tb where status = '条件' and address = '条件' 
         - select * from tb where status = '条件' 
         - select * from tb where address = '条件'
      - 索引失效（没有完全依据最左原则）
         - select * from tb where name = '条件' and address = '条件'
            - 它也走了索引，但是索引的 key_len 比全部索引字段使用的情况小，因为只有 name 索引生效
      - 索引失效2（范围查询右边的列，不能使用索引）
         - select * from tb where name = '条件' and status > '1' and address = '条件'
            - 它也走了索引，但是索引的 key_len 比全部索引字段使用的情况小，因为 statu 使用了范围，所以 address 失效
      - 索引失效3（字符串不加单引号）
         - select * from tb where name = '条件' and status > 1 
         - 使用了索引，但是 status 没有使用索引，因为底层把 1 进行隐式类型转换，所以status失效
      - 索引失效4（索引进行了计算）
         - select * from tb where substring(name,'kkk') = 'aaakkk'
            - 索引失效，因为 name 进行了计算
      - 覆盖索引，尽量使用覆盖索引，即只访问索引存在的字段，不查询根索引无关的字段
         - select * from tb where name = '条件' # 会走索引，而且 Extra 会是 Using index condition（用到了索引，但是返回的数据有索引之外的，所以还是需要查询表数据）
         - select name,status,address from tb where name = '条件' # Extra 会是 Using where;Using index （用到了索引，返回数据需要回表查询，但是因为字段已经是索引了，所以不需要回表查询了，直接索引取值）
         - select name from tb where name = '条件' # Extra 会是 Using where;Using index（同上）
         - select name,status from tb where name = '条件' # Extra 会是 Using where;Using index（同上）
         - select name,address from tb where name = '条件' # Extra 会是 Using where;Using index（同上）
         - select name,status,address from tb where name = '条件' # Extra 会是 Using where;Using index（同上）
         - select name,status,address, password from tb where name = '条件' # Extra 会是 Using index condition，因为 password 不是，但是查询中使用了索引，但是返回的数据 password 不是索引，所以需要回表查询
      - 条件中，or前面的是索引，后面的不是索引则整个失效
         - select * from tb where name = '条件' or password = '条件'
      - like 模糊查询引起的索引失效
         - 索引有效
            - select * from tb where name like '值%' # 索引生效
            - select * from tb where name like '%值' # 索引生效
         - %值% 引起的索引失效解决方案（用覆盖索引）
            - select name from tb where name like '%值%' # 索引失效，索引失效
            - select id from tb where name like '%值%' # 索引生效
            - select id,name from tb where name like '%值%' # 索引生效
            - select id,name,status from tb where name like '%值%' # 索引生效
            - select id,name,status,address from tb where name like '%值%' # 索引生效
            - select id,name,status,address, password from tb where name like '%值%' # 索引失效，因为 password 不是索引
      - 单例索引和多例索引的选择
            - 如果 name,status,address 存在三个创建的联合索引，那么在三个值匹配的时候会完整地使用这个索引
            - 如果三个字段分别有自己的单个索引，那么在三个值匹配时候会用辨识度高的索引
   - name 单独索引
      - 走全表扫描比索引快，那么它会走全表扫描
            - 假如数据有10000 条，name 字段： 9990 条是 'A'，10 条是 'B'
            - select * from tb where name='A' 不走索引（因为，大多数是 'A' 还不如全表扫）
            - select * from tb where name='B' 不走索引（因为，只有少数是 'B' 走索引更快）
      - is null 和 is not null
         - 和上面的情况类似，如果在索引字段的值在数据分布中占少数则走索引，占多数则不走索引
      - in 和 not in
         - 和上面的情况类似，如果在索引字段的值在数据分布中占少数则走索引，占多数则不走索引

* 查看索引的使用情况
   - show <global> status like 'Handler_read%'      # 查询当前<全局>会话的索引使用情况
   - 查询的结果解析
      1. Handler_read_first 
         - 索引中第一条被读的次数，如果较高，表示服务器正执行大量全索引扫描（这个值越低越好）
      2. Handler_read_key 
         - 如果索引正在工作，这个值代表一个行被索引值读的次数，如果值越低，
         - 表示索引得到的性能改善不高，因为索引不经常使用（这个值越高越好）
      3. Handler_read_next 按照键顺序读下一行的请求数，
         - 如果你用范围约束或如果执行索引扫描来查询索引列 ，该值增加
      4. Handler_read_prev 
         - 按照键顺序读前一行的数请求数，该读方法主要用于优化 ORDER BY ... DESC
      5. Handler_read_rnd 
         - 根据固定位置读一行的请求数，如果你正在大量查询并需要对结果进行排序该值较高，
         - 你可能使用了大量需要mysql扫描整个表的查询或你的连接没有正确使用键，这个值较高，
         - 意味着运行效率低，应该建立索引来补救
      6. Handler_read_rnd_next 
         - 在数据文件中读成下一行的请求数，如果你正在大量的表扫描，
         - 该值较高，通常说明你的表索引不正确或写入的查询没有利用索引

* sql 优化
   - 导入数据
      1. load data local infile '数据文件绝对路径' into table 表名 fields terminated by ',' lines terminated by '\n'
         - 数据文件一行数据以 逗号  分隔，以换行符分行，因为索引是B+树，所以建议数据是以id有序排列的
         - 在导入时可以关闭唯一性索引校验，导入结束后再设置回来 SET UNIQUE_CHECKS=0，导入后 SET UNIQUE_CHECKS=1
      2. 插入多条数据时
         - INSERT 语句的 VALUES 可以多个数据之间以,相隔例如：INSERT INTO table_name VALUES(data1,data2,...)[,(data1,data2,...),...]
         - 也可以在事务中进行数据插入
            ```
            start transaction;
            insert ...;
            insert ...;
            insert ...;
            ...
            commit;
            ```
   - order by 的优化
      - 假如 联合索引 (age,salary)
         - select * from tb order by age 索引失效
         - select * from tb order by age, salary 索引失效
         - select id[,age,salary] from tb order by age[, salary] 可以使用到联合索引（覆盖索引）
         - select id[,age,salary] from tb order by age asc, salary desc （注意排序的方向不同）# 联合索引会使用，extra 会是 Using index;Using filesort
         - select id[,age,salary] from tb order by age desc, salary asc （注意排序的方向不同）# 联合索引会使用，extra 会是 Using index;Using filesort
         - select id[,age,salary] from tb order by salary, age（注意排序的字段和索引顺序不一样）# 联合索引会使用，extra 会是 Using index;Using filesort
      - 假如 联合索引 (age,salary)
         - Filesort 的优化
            1. 两次扫描算法：mysql4.1 之前，使用该排序首先根据条件取出排序字段和指针信息，然后在排序区 sort buffer 中排序，如果内存不够则在临时表 temporary table 中存储排序，完成排序后再根据行指针读取记录，可能会导致大量的I/O
            2. 一次扫描算法：一次取出满足条件的所有字段，然后在排序区 sort buffer 中排序后直接输出结果集，排序时内存开销较大，但是排序效率比两次扫描算法要高
         - mysql 通过比较系统变量 max_length_for_sort_data 的大小和 Query 语句取出的字段总大小，来判定是否那那种排序算法，如果max_length_for_sort_data 更大，那么使用第二种优化之后的算法，否则使用第一种

   - group by 的优化
      - 与 order by 相比，group by 主要只是多了排序之后的分组操作，当然，如果在分组时候还使用了其他的一些聚合函数，那么还需要一些聚合函数的计算。所以，在 group by 的实现过程中，与 order by 一样也可以利用到索引
      - 如果在查询包含 group by 但是用户想要避免排序结果的消耗，则可以执行 order by null 禁止排序
      - age 和 salary 都没有索引的情况
         - select age,count(*) from tb group by age; # Extra 是 Using temporary;Using filesort
         - select age,count(*) from tb group by age order by null; # Extra 是 Using temporary

   - 嵌套查询的优化
      - 尽量少使用子查询，多用多表连接查询
      - 例子1
         ```
         explain select * from user where id in (select user_id from user_role)

         select_type   table        type    possible_key  key             key_len ref             rows  extra
         simple        user         ALL     primary       null            null    null            6     Using where
         simple        <subquery2>  eq_ref  <auto_key>    <auto_key>      99      demo_02.user.id 1     null
         materialized  user_role    index   fk_ur_user_id fk_ur_user_id   99      null            6     Using index

         优化为：select * from user u, user_role ur where u.id = ur.user_id
         ```

   - 优化 or
      - 对于包含 or 的查询子句，如果要利用索引。则 or 之间的每个条件都必须用到索引，而且不能使用到复合索引；如果没有索引，则应该考虑增加索引
      - 例子1
      ```
      explain select * from user where id = 1 or name = 'Tom' 结果为 extra 是 Using where，索引未生效
      优化为：select * from user where id = 1 union select * from user where name = 'Tom'
      ```

   - 分页查询的优化
      - 一般分布查询时，通过创建覆盖索引能够比较好地提高性能。一个常见问题是 limit 200000,10，此时需要mysql排序前 200010 记录，仅仅返回 200000-200010 的记录，其他记录选择，查询排序的代价非常大
      - 优化思路一
         - 在索引上完成排序颁页操作，最后根据主键关联回原表查询所需要的其他列内容
         - select * from tb t, (select id from tb order by id limit 200000,10) t2 where t.id = t2.id
      - 优化思路二
         - 该方案适用于主键自增的表，可以把 limit 查询转换成某个位置的查询
         - 但是缺点是，如果中间的id有删减并且id 不是严格的有序的完全数据，则计数会有问题
         - select * from tb where id > 200000 limit 10;

   - 使用sql提示
      - USE INDEX：select * from tb use index(索引名) where ...（只是提供 数据库的参考索引，如果系统判断不走指定索引更好则指定也不生效）
      - IGNORE INDEx：select * from tb ignore index(索引名) where ...（在sql执行时，会忽略指定的索引）
      - FORCE INDEX：select * from tb force index(索引名) where ...（在sql语句执行时会强制使用指定的索引）

   - 缓存
      - 命令
         - show variables like 'have_query_cache' # 查看当前数据库是否支持缓存
         - show variables like 'query_cache_type' # 查看当前数据库是否开启缓存
         - show variables like 'query_cache_size' # 查询缓存的大小
         - show status like 'Qcache%'             # 查询缓存的状态信息
      - mysql 查询缓存默认是关闭的，需要手动配置参数 query_cache_type，来开启查询缓存，query_cache_type 该参数的可聚会有三个
         - OFF 或 0 查询缓存功能关闭
         - ON 或 1 查询缓存功能打开，SELECT 的结果符合缓存条件即会缓存，否则，不予缓存，显式指定 SQL_NO_CACHE，不予缓存
         - DEMAND 或 2 查询缓存功能按需进行，显式指定SQL_CACHE 的 SELECT 语句才会缓存；其它均不予缓存
      - 配置
         - /usr/my.cnf 配置中，增加以下配置 query_cache_type=1 再重启
         - 可以在 select 语句中指定两个与查询缓存相关的选项
            - SQL_CACHE：如果查询结果是可缓存的，并且 query_cache_type 系统变量的值为 ON 或 DEMAND，则缓存查询结果（如果 为 ON，即使不加 SQL_CACHE，那么它也是自动缓存的）
            - SQL_NO_CACHE：服务器不使用查询缓存。它既不检查查询缓存，也不检查结果是否已缓存，也不缓存查询结果
            ```
            SELECT SQL_CACHE id,name FROM user;
            SELECT SQL_NO_CACHE id,name FROM user;

            ```
         - 缓存失效
            ```
            # 注意查询语句必须完全一样，有一个字符不一样都不行
            select count(*) from user;
            Select count(*) from user;

            # 当查询语句中有不确定时不会缓存，例如：now(),current_data(),curdate(),curtime(),rand(),uuid(),user(),database() 等
            select * from user where updatetime < now() limit 1;

            # 查询不使用任何表查询，不会缓存信息
            select 'A' as data

            # 查询mysql,information_schema 或 performance_schema 数据库中的表时，不会走查询缓存
            select * from information_schema.engines;

            # 在存储的函数，触发器或事件的主体内执行的查询
            # 如果表更改，则使用该表的所有高速缓存查询都将变为无效并从高速缓存中删除，这包括使用 merge 映射到已更改表的查询，
              一个表可以被许多类型的语句，如被改变INSERT,UPDATE,DELETE,TRUNCATE TABLE, ALTER TABLE, DROP TABLE 或 DROP DATABASE
            ```
* 数据库优化
   - MyISAM 内存优化
      - show variables like '下面的变量其中之一'
         - key_buffer_size 决定 myisam 索引块缓存区的大小，直接影响到 myisam 表的存取效率，可以在 mysql 参数文件中设置 key_buffer_size 的值对于一般myisam数据库，建议至少将1/4可用内存分配给key_buffer_size
         - read_buffer_size 如果需要经常顺序扫描myisam表，可以通过增加 read_buffer_size 的值来发送性能，但需要注意的是 read_buffer_size 是每个 session 独占的，如果默认值设置太大，就会造成内存浪费
         - read_rnd_buffer_size 对于需要做排序的myisam表的查询，如带有 order by 子句的sql，适当增加 read_rnd_buffer_size 的值，可以发送此类的sql性能，但需要注意的是 read_rnd_buffer_size 是每个 session 独 占的，如果默认值设置太大，就会造成内存浪费
   - Innodb 内存优化
      - Innodb 用一块内存区做IO缓存池，该缓存池不仅用来缓存Innodb的索引块，而且也用来缓存Innodb的数据块
      - show variables like '下面的变量其中之一'
         - innodb_buffer_pool_size 该变量决定了 innodb 存储引擎表数据和索引数据的最大缓存区大小，在保证操作系统及其他程序有足够内存可用的情况下，innodb_buffer_pool_size 值越大，缓存命中率越高，访问innodb表需要的磁盘I/O就越少，性能越高
         - innodb_log_buffer_size 决定了 innodb 重做日志缓存的大小，对于可能产生大量更新记录的大事务，增加它的大小，可以避免innodb在事务提交前就执行不必要的日志写入磁盘操作
   - Mysql 并发参数调整（在 my.cnf 中设定参数）
      - max_connections 最大连接数
      - back_log 当请求mysql的连接数达到了 max_connections，那么新来的请求会存在堆栈中，以等待某一连接释放资源，该堆栈的数量即 back_log，如果等待连接的数量超过 back_log，将不被授予连接资源，将会报错
      - table_open_cache 用来控制所有sql语句执行线程可打开表缓存的数量，而在执行 sql 语句时，每一个sql执行线程至少要打开一个表缓存，该参数的值应该根据设置的最大连接数 max_connections 以及每个连接执行关联查询中涉及的表的最大数量来设定
         - 即一个sql执行的时候可能会操作一张表或多张表，那么这个参数就是可打开的表最大数量（注意这个参数是所有连接数的各自打开表的个数之和）
      - thread_cache_size 为了加快连接数据库的速度，mysql会缓存一定数量的客户服务线程以备重用，通过参数 thread_cache_size 可控制mysql缓存客户服务线程的数量（相当于是一直存活的线程池的核心线程数）
      - innodb_lock_wait_timeout 该参数是用来设置 innodb 事务等待行锁的时间，默认值是 50ms，可以根据需要进行动态设置，对于需要快速反馈的业务系统来说，可以将行锁的等待时间调小，以避免事务长时间挂起，对于后台运行的指处理程序来说，可以将行锁的等待时间调大，以避免发生大的回滚操作


* 视图
   - 是一张虚拟的表，是 select 的封装
   - 假设有表
      ```
      create user {
        id int,
        name varchar(10) comment '用户名',
        address varchar(10) comment '用户地址',
        age int comment '用户年龄',
        primary key(id)
      }
      create kongfu {
        id int,
        name varchar(10) comment '功夫名',
        level int comment '功夫等级',
        owner_id comment '与 user 表 id 关联',
        primary key(id)
      }
      ```
   - 虽然视图可以更新，但是不建议更新，因为本身就是为了提供查询的
   - 创建语法
      ```
      create [OR REPLACE] [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}]
      VIEW view_name [(column_list)]
      AS select_statement
      [WITH [CASCADED | LOCAL ] CHECK OPTION]
      ```
   - 修改视图语法
      ```
      ALTER [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}]
      VIEW view_name [(column_list)]
      AS select_statement
      [WITH [CASCADED | LOCAL] CHECK OPTION]
      
      选项：
      WITH [CASCADED | LOCAL} CHECK OPTION 决定了是否允许更新数据使记录不再满足视图的条件
      LOCAL: 只要满足本视图的条件就可以更新
      CASCADED: 必须满足所有针对该视图的所有视图的条件才可以更新（默认值）
      ```
   - 查看视图
      - SHOW TABLES; // 会连同表一起查看（无法区分是表还是视图）
      - SHOW CREATE VIEW view_name // 查看视图的创建语句
   - 删除视图
      - DROP VIEW [IF EXISTS] view_name [,view_name2,...] [RESTRICT | CASCADED]
      - 示例，删除视图 view_user_kongfu
         ```
         DROP VIEW view_user_kongfu
         ```
* 存储过程
   - 存储过程和函数是 事先经过编译并存储在数据库中的一段sql语句的集合，调用存储过程和函数可以简化应用开发人员的很多工作，
   - 减少数据在数据库和应用服务器之间的传输，对于提高数据处理的效率是有好处的
   - 存储过程和函数的区别在于函数必须有返回值，而存储过程没有
      - 函数：是一个有返回值的过程
      - 过程：是一个没有返回值的函数
   - 存储过程的增删改查指令
      - 注意：sql 的默认语法结束符是“;”，所以在存储过程中要处理结束符
         - delimiter $ # 将 $ 替换 了 ;
         - 此时 select * from user$ 才会运行，select * from user; 不能运行
      - 创建存储过程
         ```
         # delimiter $ 之后示例
         CREATE PROCEOURE procedure_name ([proc_parameter[...]])
         begin
           sql 语句 和 其它逻辑过程;
         end$
         ```
         ```
         # delimiter $ 之后示例
         create procedure pro_test()
         begin
           select 'Linux' AS result_data;
         end$
         ```
      - 调用存储过程 
         - call pro_test()$ # 注意这里的结束符已经被替换为 $
      - 查看存储过程
         - select name from mysql.proc where db='库名' // 查询 db_name 这个库的所有的存储过程
         - show procedure status \G; // 查询存储过程的状态信息
         - show create procedure [库名.]存储过程名 \G; // 查看存储过程的内容（不指定库名就是当前所在的库）

      - 删除存储过程
         - DROP procedure [IF EXISTS] 存储过程名;
   - 存储过程的语法结构
      - 变量
         - DECLARE
            - 通过 DECLARE 可以定义一个局部变量，该变量的作用范围只能在 BEGIN...END 块中
            - DECLARE var_name[...] type [DEFAULT VALUE]
               ```
               # 声明存储过程，声明变量
               CREATE PROCEDURE pro_test()
               BEGIN
                 DECLARE num int default 10
                 select concat('num的值为：', num);
               END$

               # 声明存储过程，赋值
               CREATE PROCEDURE pro_test2()
               BEGIN
                 DECLARE num int default 0;
                 SET num = num + 10;
                 select num;
               END$
               ```
         - SET
            - 直接赋值使用 SET，可以赋常量 或者 赋表达式，具体语法如下
            - SET var_name = expr [, var_name = expr] ...
               ```
               # 声明存储过程，赋值常量
               CREATE PROCEDURE pro_test3()
               BEGIN
                 DECLARE NAME varchar(20);
                 SET NAME = 'LINUX';
                 SELECT NAME;
               END$
               ```
               ```
               # 声明存储过程 ，赋值为一个查询
               CREATE PROCEDURE pro_test4() 
               BEGIN
                 DECLARE countnum int;
                 select count(1) into countnum from 库名;
                 select countnum;
               END$
               ```
      - IF 条件判断
         ```
         # 语法格式
         if search_condition then statement_list
         [elseif search_condition then statement_list]...
         [else statement_list]...
         end if;
         ```
         ```
         # 需求
         # 180 及以上 --> 身材高挑
         # 170-180 --> 标准身材
         # 170 以下 --> 身材一般
         
         # 声明存储过程，有if语句
         CREATE PROCEDURE pro_test5()
         BEGIN
           DECLARE height int default 175;
           DECLARE description varchar($0) default '';
           IF height >= 180 then
             set description = '身材高挑';
           ELSEIF height >= 170 and height < 180 then
             set description = '标准身材';
           ELSE
             set description = '身材一般';
           END IF;
           SELECT CONCAT('身高 ', height, ' 对应的身材类型为：',description);
         END$
         ```


























* 数据库锁
   - show open tables; 查看锁的争用情况
   - 锁类型
      - 表级锁：偏向 Myisam 存储引擎，开销小，加锁快；不会出现死锁，锁定粒度大，发生锁冲突的概率最高并发度最低
      - 行级锁：偏向 Innodb 存储引擎，开销大，加锁慢；会出现死锁，锁定粒度量小，发生锁冲突的概率最低，并发度也最高
      - 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁，锁粒度界于表锁和行锁之间，并发度一般
   - MYISAM
      - 默认用的是 表锁
      - 概述
         - 加读锁：lock table table_name read;
         - 加写锁：lock table table_name write;
         - 解锁：unlock tables;
         - 假如有两张表 book 和 user
            - 读锁
               - 一个会话先对 book 加读锁，然后在当前会话中查询 user 是不行的的，
               - 因为已经持有了 book 的锁（相当于12306里抢到了票还不付款却还要抢其它的票）
               - 如果 book 的读锁没有释放，那么在当前会话或其它会话进行 book 表中数据修改是不能成功的，因为 book 已经被上锁了
            - 写锁
               - 一个会话先对 book 加写锁，然后在当前会话中查询或更新，插入是可以的
               - 另一个会话对 book 进行查询或修改都会阻塞，因为写锁是排他锁
   - Innodb
      - 默认用的是 Next-key Lock
      - set autocommit=0 关闭事务自动提交
      - 行锁特点：偏向Innodb 存储引擎，开销大，加锁慢；会出现死锁；锁定粒度量小，发生锁冲突的概率最低，
         - 并发度也最高，Innodb与Myisam的最大不同有两点：一是支持事务，二是采用了行级锁
      - 事务
         - 事务及其ACID属性，事务是由一组sql语句组成的逻辑处理单元
         - 事务具有以下4个特性，简称事务ACID属性
            - 原子性（Atomicity）事务是一个原子操作单元，其对数据的修改，要么全部成功，要么全部失败
            - 一致性（Consistent）事务开始和完成时，数据都必须保持一致状态
            - 隔离性（Isolation）数据库系统提供一定的隔离机制，保证事务不在受外部并发操作影响的“独立”环境下运行
            - 持久性（Durable）事务完成之后，对于数据的修改是永久的
      - Innodb 行锁争用情况
         - show status like 'Innodb_row_lock%'
            - Innodb_row_lock_current_waits 当前正在等待锁定的数量
            - Innodb_row_lock_time 从系统到现在锁定总时间长度
            - Innodb_row_lock_time_avg 每次平均所花平均时长
            - Innodb_row_lock_time_max 从系统启动到现在等待最长的一次所花的时间
            - Innodb_row_lock_waits 系统启动后到现在总共等待的次数
         - 当等待次数很高，而且每次等待的时长也不小的时候，
         - 我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划

   - 锁的机制和加锁原理
      - 不同隔离等级的情况
         - `select * from test where id=?` 如果id是唯一索引，那么在 RC,RR 隔离级别下，是无加锁查询
            - 如果是在 Serializable 级别下，则是 共享锁
      - 锁的划分
         - 粒度划分：行锁，表锁，页锁
         - 使用方式划分：共享锁，排它锁（悲观锁的一种实现）
            - 乐观锁：
               - 认为修改情况少，而读取多，所以更新时才加以认证，用一个自增号表示，
               - 更新时进行比较自增号是否和自己的自增号一致，一致则更新信息再对自增号加一
            - 悲观锁：
               - 认为修改情况很多，所以在每次进入逻辑时都要加锁
               - 例子
                  - 共享锁(S锁)：只有读取时才加锁，加锁后自己和其它线程只能读不能写，
                     - 且其它线程不能再对此加共享或互斥锁
                  - 互斥锁(X锁)：
                     - 也称为排它锁
                     - 进入逻辑前就加锁，其它线程增删改都不能获取锁
         - 还有两种思想上的锁：乐观锁，悲观锁
         - InnoDB中有身居种锁类型：Record Lock, Gap Lock, Next-key Lock
            - Record Lock：在索引记录上加锁
            - Gap Lock：间隙锁
            - Next-key Lock：Record Lock + Gap Lock
            - 注意：Innodb 默认的锁是 Next-key Lock
      - 锁的划分
         - 行锁：行锁是Mysql中锁定粒度最细的一种锁，只针对当前操作的行加锁，行级锁能减少冲突，粒度最小，但加锁开销最大，有可能死锁
            - 共享锁 S锁
            - 互斥锁 X锁
         - 表锁：粒度最大的一种锁，表示当前的操作对整张表加锁，资源开销比行锁小，不会死锁，但是发生锁冲突概率大（Innodb 默认是行锁）
            - 共享锁 S锁
            - 互斥锁 X锁
         - 页锁：介于行锁和表级锁中间的一种锁。表级锁速度快，冲突多；行级锁速度慢，冲突少。所以取了折衷的页级锁，一次锁定相邻的一组记录
         - 乐观锁和悲观锁
      - Record Lock,Gap Lock,Next-key Lock
         - Record Lock
            - 单条索引上加锁，record lock 永远锁的是索引，而非数据本身，如果innodb表中没有索引，那么会自动创建一个隐藏的聚集索引，锁住的是
            - 这个聚集索引。所以说当一条sql没有走任何索引时，那么将会在每一条聚集索引后面加X锁，这个类似于表锁，但原理上和表锁应该是完全不同的
         - Gap Lock
            - 注意，对于一个二级索引，不仅对临近索引的区间进行加锁，还对临近索引对应的id形成的区间进行加锁
            - https://www.cnblogs.com/crazylqy/p/7821481.html
         - Next-Key Lock
            - 这个锁机制其实就是 Record Lock + Gap Lock，既锁住记录本身还锁住索引之间的间隙

   - 死锁
      - [死锁解析](https://www.cnblogs.com/LBSer/p/5183300.html)
      - 我们 mysql 用的存储引擎是 innodb，从日志中看，innodb主动探知到死锁，并回滚了某一苦苦等待的事务。问题来了，innodb是怎么探知死锁的？
         - 直观看方法是在两个事务相互等待时，当一个等待时间超过设置的某一阀值时，对其中一个事务进行回溯，另一个事务能继续执行。
         - 这种方法简单有效，在innodb中，参数innodb_lock_wait_timeout用来设置超时时间
         - 仅用上述方法来检测死锁太过被动，innodb还提供了wait-for graph 算法来主动进行死锁检测，每当加锁请求无法立即满足需要并进入等待时，wait-for graph 算法都会被触发
      - wait-for graph 原理
         - 概念
            - 我们怎么知道上图中四辆车是死锁的？他们相互等待对方的资源，而且形成环路！
            - 我们将每辆车看为一个节点，当节点1需要等待节点2的资源时，就生成一条有向边指向节点2，最后形成一个问题。
            - 我们只要检测这个有向图是否出现环路即可，出现环路就是死锁！这就是wait-for graph 算法
         - 概念图
            ```
            2 <--- 1
            |      ^
            v      |
            3 ---> 4
            innodb将各个事务看为一个个节点，资源就是各个事务占用的锁，当事务1需要等待事务2的锁时，
            就生成一条有向边从1指向2，最后形成一个有向图
            ```
      - 锁与索引的关系 
         - 假设我们有一张消息表（msg），里面有3个字段。假设id是主键，token是非唯一索引，message没有索引
            ```
            id:bigint   token:varchar(30)   message:varchar(4096)
            ```
         - innodb对于主键使用了聚簇索引，这是一种数据存储方式，表数据是和主键一起存储，
            - 主键索引的叶结点存储行数据，对于普通索引，其叶子节点存储的是主键值
               ```
                    聚簇索引                   二级索引
               id  token  message             token  id
               1   aaa    你好                aaa    1
               2   axd    怎么申请退款        asd    4
               3   cvs    怎么处理            axd    2
               4   asd    订单号是多少        cvs    3
               5   cvs    谢谢                cvs    5
               ```
         - delete from msg where id = 2;
            ```
            由于id是主键，因此直接锁住整行记录即可
                   id  token  message
                   1   aaa    你好
            X锁 -->2   axd    怎么申请退款
                   3   cvs    怎么处理
                   4   asd    订单号是多少
                   5   cvs    谢谢
            ```
         - delete from msg where token = 'cvs';
            ```
            由于  token 是二级索引，因此首先锁住二级索引（两行），接着会锁住相应主键所对应的记录
                       二级索引                    聚簇索引                  
                      token  id               id  token  message             
                      aaa    1                1   aaa    你好                
                      asd    4                2   axd    怎么申请退款        
                      axd    2            *-->3   cvs    怎么处理            
               /*---->cvs    3            |   4   asd    订单号是多少        
            X锁------>cvs    5       X锁--*-->5   cvs    谢谢                
            ```
         - delete from msg where message = '订单号是多少';
            ```
            message 没有索引，所以走的是全表扫描过滤，这时表上的各个记录都将添加上X锁
                       id  token  message
                 /*--->1   aaa    你好
                /-*--->2   axd    怎么申请退款
            X锁 *-*--->3   cvs    怎么处理
                \-*--->4   asd    订单号是多少
                 \*--->5   cvs    谢谢
            ```
      - 锁与隔离级别的关系
         - 幻读
            ```
            事务A                                     事务B
            begin                                     begin
            ----------------------------------------------------------------
            select * from msg where
            token='asd'
            id|token|message
            4 |asd  |订单号是多少
            ----------------------------------------------------------------
            update msg set message='订单'
            where token='asd'
            ----------------------------------------------------------------
                                                      insert into msg values
                                                      (null,'asd','hello');
                                                      commit;
            ----------------------------------------------------------------
            select * from msg where
            token='asd'
            id|token|message
            4 |asd  |订单号是多少
            6 |asd  |hello

            产生了幻读
            ```
         - innodb的RR隔离级别避免幻读发生，用 gap 锁处理
            - 在事务A执行 update msg set message='订单' where token='asd'; 时
            - innodb首先会和RC级别一样，给索引上的记录添加上X锁，此外，还在非唯一索引 'asd' 与相邻两个索引
            - 的区间加上锁，这样，当事务B在执行 insert into msg values(null,'asd','hello');commit;时，会
            - 首先检查这个区间是否被锁上，如果被锁上，则不能立即执行，需要等待该gap锁被释放
            - 图示
               ```
                                 |token:varchar(30)|id:bigint|        |id:bigint|token:varchar(30)|message:varchar(4096)|
               GAP锁(aaa,asd)--*\|aaa              |1        |        |1        |aaa              |你好                 |
                           X锁-->|asd              |4        |        |2        |axd              |怎么申请退款         |
                                /|axd              |2        |  X锁-->|3        |cvs              |怎么处理             |
               GAP锁(asd,axd)--* |cvs              |3        |        |4        |asd              |订单号是多少         |
                                 |cvs              |5        |        |5        |cvs              |谢谢                 |
               ```
      - 死锁成因
         - 不同表相同记录行锁冲突
            - 事务A和事务B操作两张表，但出现循环等待情况
               ```
               事务A                                            事务B
               begin                                            begin
               delete from b1 where id=1;                       
                                                                update msg set message='订单' where token='asd'      
               update msg set message='订单' where token='asd'
                                                                delete from b1 where id=1;
               ```
         - 相同表记录行锁冲突
            - 之前遇到两个在执行数据批量更新时，jobA处理的id列表为[1,2,3,4]，而job处理的id列表为[8,9,10,4,2]，这样就造成了死锁
               ```
               事务A                                            事务B
               begin                                            begin
               update from b1 where id=1;
                                                                update from b1 where id=2;
               update from b1 where id=2;
                                                                update from b1 where id=1;
               ```
         - 不同索引锁冲突
            - 这种情况比较隐晦，事务A在执行时，除了在二级索引加锁外，还会在聚簇索引上加锁，在聚簇索引上加锁的顺序是[1,4,2,3,5]，而
            - 事务B执行时，只在聚簇索引上加锁，加锁顺序是[1,2,3,4,5]，这样就成了死锁的可能性
               ```
               事务A                                            事务B
               begin                                            begin
               update msg wet message='订单' where token>'aaa'  delete from msg whre id>=1;
               ```
         - gap锁冲突
            - innodb在RR级别下，如下情况也会产生死锁，比较隐晦
            ```
               事务A                                               事务B
               begin                                               begin
               update msg set message='订单' where token='asd'
                                                                   update msg set message='订单' where token='aaa'
               insert into msg values(null,'aad','hello');commit;
                                                                   insert into msg values (null,'bsa','hello');commit;
            ```
      - 如何尽可能避免死锁
         1. 以固定的顺序访问表和行，比如对第二节两个 job 批量更新的情形，简单方法是对id列表先排序，
            - 后执行，这样就避免了交叉等待锁的情形，又比如对于3.1节的情形，
            - 将两个事务的sql顺序调整为一致，也能避免死锁
         2. 大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小
         3. 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁概率
         4. 降低隔离级别。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，
            - 可以避免掉很多因为gap锁造成的死锁
         5. 为表添加合理的索引。可以看到如果不走索引将会为表的每一行记录添加上锁，死锁的概率大大增大


* SQL 执行技巧
   - 编写顺序：SELECT-DISTINCT-FROM-JOIN-WHERE-GROUP BY-HAVING-ORDER BY-LIMIT
   - 执行顺序：FROM-ON-<join_type> JOIN-WHERE-GROUP BY-HAVING-SELECT DISTINCT-LIMIT

* MYSQL 工具
   1. mysql [options] -h查询的mysql服务器地址 -u用户名 -p密码 -P端口 库名 -e "执行sql"
      - -e 参数可以不进入会话的形式执行sql语句，否则进行会话模式
   2. mysqladmin -h服务器地址 -u用户名 -p密码 -P端口 使用参数
      - 使用参数
         - version 查询版本号
         - create 库名（创建库）
         - drop 库名（删除库）
   3. mysqlbinlog 由于服务器生成的二进制日志文件以二进制格式保存，所以如果想要检查这些文本的文本格式，就会使用到mysqlbinlog日志管理工具
      - mysqlbinlog [options] log-files1 log-files ...
      - options
         - -d, --database=name：指定数据库名称，只列出指定的数据库相关操作
         - -o, --offset=#：忽略掉日志中的前n行命令
         - -r, --result-file=name：将输出的文本格式日志输出到指定文件
         - -s, --short-form：显示简单格式，省略掉一些信息
         - --start-datatime=date1 --stop-datetime=date2：指定日期间隔内的所有日志
         - --start-position=pos1 --stop-position=pos2：指定位置间隔内的所有日志
   4. mysqldump 客户端工具用来备份数据库或在不同数据库之间进行数据迁移，备份内容包含创建表，及插入表的sql语句
      - mysqldump [options] db_name [tables]
      - mysqldump [options] --database/-B db1 [db2 db3 ...]
      - mysqldump [options] --all-database/-A
      - 连接选项
         - -u, --user=name 指定用户名
         - -p, --password[=name] 指定密码
         - -h, --host=name 指定服务器IP或域名
         - -P, --port=# 指定连接端口
      - 输出内容选项
         - --add-drop-database # 在每个数据库创建语句前加上 Drop database 语句
         - --add-drop-table # 在每个表创建语句前加上 Drop table 语句，默认开启；不开启（--skip-add-drop-table）
         - -n, --no-create-db # 不包含数据库的创建语句
         - -t, --no-create-info # 不包含数据表的创建语句
         - -d, --no-data # 不包含数据
         - -T, --tab=路径名 # 自动生成两个文件：一个.sql文件，创建表结构的语句；一个.txt文件，数据文件，相当于select into outfile
      - 示例
         - mysqldump -uroot -p123456 test my_user --add-drop-database --add-drop-table > a.txt # 把 test 库的 my_user 表输出到 a.txt 文件，并在其中有删除库和表预先内容
         - mysqldump -uroot -p123456 -T /temp test my_user # 把 test 库的 my_user 表输出到 /temp 目录下并生成 .txt 和 .sql 文件

   5. mysqlimport 和 source 命令
      - mysqlimport 是客户端数据导入工具，用来导入 mysqldump 加 -T 参数后导出的文本文件
      - mysqlimport [options] db_name textfile1 [textfile2...]
         - 示例：mysqlimport -uroot -p123456 test /tmp/city.txt
      - 如果需要导入 sql 文件，可以使用 mysql 中的 source 指令：
         - 先登录进mysql
         - source /root/tb_book.sql
   6. 严重注意：“mysqldump -T 路径” 和 “mysqlimport 库名 文件名”
      - 导出路径权限受限
         - 一般 mysql 对这两个命令的 导出 和 导入 有文件夹限定，可以通过登录mysql后 show variables like 'secure_file_priv' 进行查看允许的路径
         - 如果路径没有值，则已经禁用了，如果影响了导出和导入则需要重设它的值
         - 如果路径有值，则导出只能导出到那个路径（路径只能是那个路径），导入时只能导入那个路径下的文件（而且要写全路径名）
      - 命令使用区别
         - mysqldump 可以导出：sql语法文件，也可以导出：sql的表结构语法文件 和 纯数据文件
         - mysqlimport 只能导入 纯数据文件
         - source 只能执行 sql语法文件

   6. mysqlshow
      - mysqlshow 客户端对象查找工具，用来很快地查找存在哪些数据库，数据库中的表，表中的列或者索引
      - mysqlshow [options] [db_name [table_name [col_name]]]
         - options
            - --count 显示数据库及表的统计信息（数据库，表，均可以不指定）
            - -i 显示指定数据库或者指定表的状态信息
      - 示例
         1. mysqlshow -uroot -p123456 --count # 查询每个数据库的表的数量及表中记录的数量
         2. mysqlshow -uroot -p123456 test --count # 查询 test 库中每个表中的字段数，及行数
         3. mysqlshow -uroot -p123456 test book --count # 查询 test 库中 book 表的详细情况

* MYSQL 日志
   - 概念
      - 在任何一种数据库中，都会有各种各样的日志，记录着数据库工作的方方面面，以帮助数据库管理员追踪数据库曾经发生过的各种事件
      - mysql 中不例外，在 mysql 中，有4种不同的日志，分别是错误日志，二进制日志（BINLOG日志），查询日志和慢查询日志，这些日志记录着数据库在不同方面的踪迹
   - 日志类型
   
      1. 错误日志
         - 错误日志是 mysql 中最重要的日志之一，它记录了当 mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。当数据库出现任何故障导致无法正常使用时，可以首先查看此日志
         - 该日志默认开启的，默认存放目录为 mysql 的数据库目录（var/lib/mysql），默认的日志文件名为 hostname.err（hostname 是主机名）
         - 指令：show variables like 'log_error%' # 得到了 variable_name 和 value 的信息，即得到错误日志的文件位置
         - 查看日志内容：tail -f value的值
   
      2. 二进制日志
         - 概念
            - 记录了所有的 DDL（数据定义语言）语句和DML（数据操纵语句）语句，但是不包括数据查询语句，此日志对于灾难时的数据恢复起着极其重要的作用，mysql的主从复制，就是通过该binlog实现的
            - 二进制日志，默认情况下是没有开启的，需要到 mysql 的配置文件中开启，并配置 mysql 日志的格式
         - 配置文件位置：/usr/my.cnf
            - 日志存放位置：配置时，给定了文件名但是没有指定路径，日志默认写入 mysql 的数据目录
            ```
               # 配置开启 binlog 日志，日志的文件前缀为 mysqlbin ----> 生成的文件名如：mysqlbin.000001 , mysqlbin.000002
               log_bin=mysqlbin
   
               # 配置二进制日志的格式，这里的可以是 STATEMENT, ROW, MIXED 之一
               binlog_format=STATEMENT
            ```
         - 日志格式
            1. STATEMENT
               - 该日志格式在日志文件中记录的都是sql语句（statement），每一条对数据进行修改的sql都会记录在日志文件中，通过mysql提供的
               - mysqlbinlog 工具，可以清晰地查看到每条语句的文件，主从复制的时候，从库（slave）会将日志解析为原文本，并在从库重新执行一次
            2. ROW
               - 该日志格式在日志文件中记录的是每一行的数据变更，而不是记录sql语句，比如，执行sql语句：update tb_book set status=1，如果是
               - STATEMENT 日志格式，在日志记录中会记录一行sql文件；如果是ROW，由于是对全表进行更新，也就是每一行记录都会发生变更，ROW格式的日志中会记录每一行的数据变更
            3. MIXED（默认格式）
               - 这是目前 mysql 默认的日志格式，即混合了 STATEMENT 和 ROW 两种格式，默认情况记录 STATEMENT，但是在一些特殊情况下采用 ROW 来进行记录。MIXED 格式能尽量利用两种模式的优点，而避开他们的缺点
         - 二进制日志的查看
            - 查看日志
               - mysqlbinlog 命令
               - 如果日志格式是 ROW，直接查看数据，是查看不懂的；可以在 mysqlbinlog 后面加上 -vv
                  - mysqlbinlog -vv 日志文件
            - 日志的删除
               1. Reset Master # 通过 Reset Master 指令删除全部 binlog 日志，删除之后，日志编号，将从 xxx.000001 重新开始
               2. purge master logs to 'mysqlbin.xxxxx'  # 该命令可以将指定编号之前的日志删除
               3. purge master logs before 'yyyy-mm-dd hh24:mi:ss' # 该命令将删除日志为 "yyyy-mm-dd hh24:mi:ss" 之前产生的所有日志
               4. 设置参数 --expire_logs_data=#，此参数的含义是设置日志的 过期天数，过了指定的天数后日志将会自动删除，这样将有利于减少 DBA 管理日志的工作量
                  - 即在 /usr/my.cnf 中进行设置
   
      3. 查询日志
         - 注意：查询日志既包含增删改，也包含查询的日志；查询日志存放在 mysql 数据存放区域
         - 查询日志中记录了客户端的所有操作语句，而二进制日志不包含查询数据的 sql 语句
         - 默认情况下，查询日志是关闭的，如果需要开启查询日志，可以设置以下配置
         - 在 mysql 的配置文件 /usr/my.cnf 中配置
            ```
            # 该选项用来开启查询日志，可选值为：0 或者 1,0 代表关闭，1 代表开启
            general_log=1

            # 设置日志的文件名，如果没有指定，默认的文件名为 host_name.log
            general_log_file=file_name
            ```

      4. 慢查询日志
         - 概念
            - 慢查询日志记录了所有执行时间超过参数 long_query_time 设置值并且扫描记录数不小于 min_examined_row_limit 的所有的 sql 语句的日志
            - long_query_time 默认为 10 秒，最小为 0，精度可以到微秒
         - 文件位置和格式
            ```
            # 该参数用来控制慢查询日志是否开启，可以取值 1 和 0,1 代表开启，0 代表关闭
            slow_query_log=1

            # 该参数用来指定查询日志的文件名
            slow_query_log_file=slow_query.log

            # 该选项用来配置查询的时间限制，超过这个时间将认为是慢查询，将需要进行日志记录，默认 10s
            long_query_time=10
            ```
         - 日志的读取
            - 和错误日志，查询日志一样，慢查询日志记录的格式也是纯文本，可以被直接读取
            - 查询 long_query_time 的值：show variable like 'long%'

* MYSQL 主从搭建
   - 主从原理
      - Master 主库在事务提交时，会把数据变更作为时间 Events 记录在二进制日志文件 Binlog 中
      - 主库推送二进制日志文件 Binlog 中的日志事件到从库的中继日志 Relay Log
      - slave 重做中继日志中的事件，将改变反映它自己的数据
   - 主从优势
      - 主库出现问题，可以快速切换到从库提供服务
      - 可以在从库上执行查询操作，从主库中更新，实现读写分离，降低主库的访问压力
      - 可以在从库中执行备份，以避免备份期间影响主库的服务
   - 双主双从
      - 只需要 M1 当 M2 的 slaver 同时 M2 当 M1 的 slaver
         - 即在两台机器上都要执行指向对方的参数的 CHAGE ... 命令
      - 配置中，M1 和 M2自增的起始偏移量应该不能相同
   - 搭建过程
      - master
         1. 在 /usr/my.cnf 中配置
            ```
            [mysqld]
            # mysql 服务id，保证整个集群环境中唯一，即节点的 id
            server-id=1

            # 开启进制日志功能，并制定 mysql binlog 日志的存储路径和文件名
            log-bin=/var/lib/mysql/mysqlbin

            # 是否只读，1 代表只读，0 代表读写
            read-only=0

            # 忽略的数据库，指不需要同步的数据库名字
            binlog-ignore-db=mysql
            binlog-ignore-db=information_schema

            # 需要复制的主数据库名字（可以不写）
            binlog-do-db=需要复制的主数据库名字

            # logbin 格式
            binlog_format=STATEMENT

            # 自增长字段每次递增的量，指自增字段的起始值，其默认值是1,取值范围是1 .. 65535
            auto-increment-increment=2
            # 自增长字段从哪个数开始，指字段一次递增多少，他的联取值范围是 1 .. 65535（如果是多 master 情况这个值不能一样）
            auto-increment-offset=1

            # 在从作为从数据库时，有写入操作也要更新二进制日志文件（因为虽然这台机器是 master，但是对于双 master 时也相当于作为其它 master 的 slave，此种情况需要设置）
            log-slave-updates

            ```
         2. 重启服务
         3. 创建同步数据的账户，并且进行授权操作
            - `GRANT REPLICATION SLAVE ON *.* to 'itcast'@'可从哪个地址进行访问本主机' identified by 'itcast'; flush privileges;`
         4. 查看 master 状态（获取的数据在配置 slaver 时有用）
            - show master status
               - File 记录同步数据的日志文件名（假设 mysqlbin.000002）
               - Position 数据记录的开始位置（假设 591）
      - slaver
         1. 在 /usr/my.cnf 中配置
            ```
            [mysqld]
            # mysql 服务id，保证整个集群环境中唯一，即节点的 id
            server-id=2

            # 开启二进制日志功能，并制定 mysql binlog 日志的存储路径和文件名
            log-bin=/var/lib/mysql/mysqlbin

            # 是否只读，1 代表只读，0 代表读写
            read-only=1

            # 忽略的数据库，指不需要同步的数据库名字
            binlog-ignore-db=mysql
            binlog-ignore-db=information_schema

            # 需要复制的主数据库名字（可以不写）
            binlog-do-db=需要复制的主数据库名字

            # logbin 格式
            binlog_format=STATEMENT

            # 自增长字段每次递增的量，指自增字段的起始值，其默认值是1,取值范围是1 .. 65535
            auto-increment-increment=2
            # 自增长字段从哪个数开始，指字段一次递增多少，他的联取值范围是 1 .. 65535
            auto-increment-offset=1

            # 开始从数据库的中继日志，因为它是从 master 的 binlog 复制到本地的 mysql-relay 日志，然后从 mysql-relay 中进行同步的
            relay-log=/var/lib/mysql/mysql-relay
            ```
         2. 重启服务
         3. 执行如下命令
            - 从机执行命令
               ```
                 CHANGE MASTER TO MASTER_HOST='master主机地址',
                 MASTER_USER='itacast',
                 MASTER_PASSWORD='itcast',
                 MASTER_LOG_FILE='查询show master status 命令结果的的 File 值',
                 MASTER_LOG_POS=查询show master status 命令结果的Position值;
               ```

            - 意思是指 master 的地址，同步数据的 账户名，密码，从 master 的哪个文件的哪个位置开始同步数据
         4. 开启同步操作
            - start slave;
            - show master status; # 查看 master 的状态
            - show slave status;
               - 查看 Slave_IO_Running: YES
               - 查看 Slave_SQL_Running: YES
         5. 命令
            - 主要命令
               - show master status # 查看 master 的配置
               - show slave status # 查看 slave 的配置
               - start slave # 启动从机从主机复制的功能
               - stop slave # 关闭从机从主机复制的功能
            - 停止从服务复制功能
               - stop slave 
            - 重新配置主从
               - stop slave 
               - reset master


